{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyNuJz2voPBjcElVJuy0PjmU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"6KLA64a60omP"},"outputs":[],"source":["from zipfile import ZipFile\n","import os\n","\n","zip_file_path = '/content/women-fashion (1).zip'\n","extraction_directory = '/content/women_fashion'\n","\n","if not os.path.exists(extraction_directory):\n","    os.makedirs(extraction_directory)\n","\n","with ZipFile(zip_file_path, 'r') as zip_ref:\n","    zip_ref.extractall(extraction_directory)\n","\n","extracted_files = os.listdir(extraction_directory)\n","print(extracted_files[:10])"]},{"cell_type":"code","source":["# correcting the path to include the 'women fashion' directory and listing its contents\n","extraction_directory_updated = os.path.join(extraction_directory, 'women fashion')\n","\n","# list the files in the updated directory\n","extracted_files_updated = os.listdir(extraction_directory_updated)\n","extracted_files_updated[:10], len(extracted_files_updated)"],"metadata":{"id":"8xaCpLt_2ESp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from PIL import Image\n","import matplotlib.pyplot as plt\n","\n","# function to load and display an image\n","def display_image(file_path):\n","    image = Image.open(file_path)\n","    plt.imshow(image)\n","    plt.axis('off')\n","    plt.show()\n","\n","# display the first image to understand its characteristics\n","first_image_path = os.path.join(extraction_directory_updated, extracted_files_updated[0])\n","display_image(first_image_path)"],"metadata":{"id":"VogWJAMl2KKl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import glob\n","\n","# directory path containing your images\n","image_directory = '/content/women_fashion/women fashion'\n","\n","image_paths_list = [file for file in glob.glob(os.path.join(image_directory, '*.*')) if file.endswith(('.jpg', '.png', '.jpeg', 'webp'))]\n","\n","# print the list of image file paths\n","print(image_paths_list)"],"metadata":{"id":"bq-zUYBY2R8z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n","from tensorflow.keras.applications.vgg16 import preprocess_input\n","from tensorflow.keras.models import Model\n","import numpy as np\n","\n","base_model = VGG16(weights='imagenet', include_top=False)\n","model = Model(inputs=base_model.input, outputs=base_model.output)\n","\n","def preprocess_image(img_path):\n","    img = image.load_img(img_path, target_size=(224, 224))\n","    img_array = image.img_to_array(img)\n","    img_array_expanded = np.expand_dims(img_array, axis=0)\n","    return preprocess_input(img_array_expanded)\n","\n","def extract_features(model, preprocessed_img):\n","    features = model.predict(preprocessed_img)\n","    flattened_features = features.flatten()\n","    normalized_features = flattened_features / np.linalg.norm(flattened_features)\n","    return normalized_features\n","\n","all_features = []\n","all_image_names = []\n","\n","for img_path in image_paths_list:\n","    preprocessed_img = preprocess_image(img_path)\n","    features = extract_features(model, preprocessed_img)\n","    all_features.append(features)\n","    all_image_names.append(os.path.basename(img_path))"],"metadata":{"id":"jXd5CBd22XJa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from scipy.spatial.distance import cosine\n","\n","def recommend_fashion_items_cnn(input_image_path, all_features, all_image_names, model, top_n=5):\n","    # pre-process the input image and extract features\n","    preprocessed_img = preprocess_image(input_image_path)\n","    input_features = extract_features(model, preprocessed_img)\n","\n","    # calculate similarities and find the top N similar images\n","    similarities = [1 - cosine(input_features, other_feature) for other_feature in all_features]\n","    similar_indices = np.argsort(similarities)[-top_n:]\n","\n","    # filter out the input image index from similar_indices\n","    similar_indices = [idx for idx in similar_indices if idx != all_image_names.index(input_image_path)]\n","\n","    # display the input image\n","    plt.figure(figsize=(15, 10))\n","    plt.subplot(1, top_n + 1, 1)\n","    plt.imshow(Image.open(input_image_path))\n","    plt.title(\"Input Image\")\n","    plt.axis('off')\n","\n","    # display similar images\n","    for i, idx in enumerate(similar_indices[:top_n], start=1):\n","        image_path = os.path.join('/content/women_fashion/women fashion', all_image_names[idx])\n","        plt.subplot(1, top_n + 1, i + 1)\n","        plt.imshow(Image.open(image_path))\n","        plt.title(f\"Recommendation {i}\")\n","        plt.axis('off')\n","\n","    plt.tight_layout()\n","    plt.show()"],"metadata":{"id":"Y18CHNlR2xw3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_image_path = '/content/women_fashion/women fashion/dark, elegant, sleeveless dress that reaches down to about mid-calf.jpg'\n","recommend_fashion_items_cnn(input_image_path, all_features, image_paths_list, model, top_n=4)"],"metadata":{"id":"nBRZNMNA3Hl9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["THANKS ME LATER~ Murtaza\n","\n","\n"],"metadata":{"id":"9WDcgnRO3UI8"}}]}